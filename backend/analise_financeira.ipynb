{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd37f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain_community) (0.3.67)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain_community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain_community) (3.12.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain_community) (0.4.4)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.4.8 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langchain-ollama) (0.5.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from ollama<1.0.0,>=0.4.8->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\bruno\\envs\\cv\\lib\\site-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install langchain_community langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570b2de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_community.llms import Ollama\n",
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58be01fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of today, November 2, 2023, the current president of Brazil is **Luiz In√°cio Lula da Silva**, often referred to as simply **Lula**. \\n\\nHe assumed office on January 1, 2023.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OllamaLLM(model=\"gemma3\")\n",
    "llm.invoke(\"who is the current president of Brazil?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decbbe37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-11</td>\n",
       "      <td>Uber* Trip</td>\n",
       "      <td>9.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>99app *99app</td>\n",
       "      <td>12.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-09</td>\n",
       "      <td>Uber Uber *Trip Help.U</td>\n",
       "      <td>31.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>Uber* Trip</td>\n",
       "      <td>8.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>Uber Uber *Trip Help.U</td>\n",
       "      <td>15.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                   title  amount\n",
       "0  2025-06-11              Uber* Trip    9.74\n",
       "1  2025-06-10            99app *99app   12.40\n",
       "2  2025-06-09  Uber Uber *Trip Help.U   31.42\n",
       "3  2025-06-08              Uber* Trip    8.46\n",
       "4  2025-06-08  Uber Uber *Trip Help.U   15.22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/Bruno/Downloads/Nubank_2025-06-19.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8345b4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Valor</th>\n",
       "      <th>Descri√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/04/2025</td>\n",
       "      <td>500.00</td>\n",
       "      <td>Transfer√™ncia recebida pelo Pix - MARGARETE MA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/04/2025</td>\n",
       "      <td>-60.00</td>\n",
       "      <td>Transfer√™ncia enviada pelo Pix - J√©ssica Diana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/04/2025</td>\n",
       "      <td>-131.30</td>\n",
       "      <td>Transfer√™ncia enviada pelo Pix - COMPANHIA PIR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/04/2025</td>\n",
       "      <td>-55.18</td>\n",
       "      <td>Pagamento de boleto efetuado - SERVICO AUTONOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06/04/2025</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>Compra no d√©bito - Meep Pa*Multi Produtor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data   Valor                                          Descri√ß√£o\n",
       "0  01/04/2025  500.00  Transfer√™ncia recebida pelo Pix - MARGARETE MA...\n",
       "1  02/04/2025  -60.00  Transfer√™ncia enviada pelo Pix - J√©ssica Diana...\n",
       "2  03/04/2025 -131.30  Transfer√™ncia enviada pelo Pix - COMPANHIA PIR...\n",
       "3  03/04/2025  -55.18  Pagamento de boleto efetuado - SERVICO AUTONOM...\n",
       "4  06/04/2025   -7.00          Compra no d√©bito - Meep Pa*Multi Produtor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'Identificador' in df.columns:\n",
    "                df.drop(columns=['Identificador'], inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6bcbcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique transactions in the Name / Description column\n",
    "unique_transactions = df[\"title\"].unique()\n",
    "len(unique_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0fa07be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['99app *99app', 'Uber Uber *Trip Help.U',\n",
       "       'Cr√©dito de parcelamento de compra', 'Sonda Salto Ii',\n",
       "       'Dia Brasil Lj', 'Dm*Crunchyroll L', 'Ppro *Microsoft', 'Adega 4d',\n",
       "       'Gustavo Moura de Sa', 'Gustavo Mattos Fortes',\n",
       "       'Parcelamento de Compra - Ppro *Microsoft - 1/2',\n",
       "       'Parcelamento de Compra - Nove de Julho Conven - 1/3',\n",
       "       'Nove de Julho Conven', 'Blablacar', 'Prohumana',\n",
       "       'Parcelamento de Compra - Sonda Salto Ii - 2/3',\n",
       "       'Parcelamento de Compra - Sonda Salto Ii - 3/3',\n",
       "       'Parcelamento de Compra - Microsoft*Subscription - 2/2',\n",
       "       'Parcelamento de Compra - Fatimo Volmir Oliveir - 7/7',\n",
       "       'Pagamento recebido'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_transactions[1:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "addfb027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transaction_name(transaction_names):\n",
    "    \"\"\"\n",
    "    Remove informa√ß√µes desnecess√°rias da transa√ß√£o ap√≥s o segundo h√≠fen\n",
    "    \"\"\"\n",
    "    # Divide a string pelos h√≠fens\n",
    "    parts = transaction_names.split(' - ')\n",
    "\n",
    "    # Se tem mais de 2 partes, mant√©m apenas as duas primeiras\n",
    "    if len(parts) > 2:\n",
    "        return ' - '.join(parts[:2])\n",
    "\n",
    "    return transaction_names\n",
    "\n",
    "def categorize_transactions(transaction_names, llm):\n",
    "    individual_transactions = [t.strip() for t in transaction_names.split(',')]\n",
    "\n",
    "    cleaned_transactions = [clean_transaction_name(t) for t in individual_transactions]\n",
    "\n",
    "    # Cria uma lista numerada para facilitar o processamento\n",
    "    numbered_transactions = []\n",
    "    for i, transaction in enumerate(cleaned_transactions, 1):\n",
    "        numbered_transactions.append(f\"{i}. {transaction}\")\n",
    "    \n",
    "    transactions_text = '\\n'.join(numbered_transactions)\n",
    "    \n",
    "    prompt = (\n",
    "        \"Voc√™ √© um especialista em contexto de conjunto de dados financeiros. \"\n",
    "        \"Seu papel √© analisar e classificar receitas e despesas do contexto econ√¥mico do indiv√≠duo. \"\n",
    "        \n",
    "        \"REGRAS IMPORTANTES:\\n\"\n",
    "        \"- Retorne EXATAMENTE no formato 'TRANSA√á√ÉO - CATEGORIA' (uma por linha)\\n\"\n",
    "        \"- Mantenha a transa√ß√£o EXATAMENTE como foi enviada, n√£o abrevie nem corte\\n\"\n",
    "        \"- Quando identificar supermercados/mercados, classificar EXATAMENTE como 'Mercado'\\n\"\n",
    "        \"- Quando identificar alimenta√ß√µes, refei√ß√µes, restaurantes e pedidos de comida (via Ifood por exemplo), classificar EXATAMENTE como 'Alimenta√ß√£o'\\n\"\n",
    "        \"- Quando identificar farm√°cia ou drogaria, classificar EXATAMENTE como 'Sa√∫de'\\n\"\n",
    "        \"- N√ÉO adicione numera√ß√£o na resposta\\n\"\n",
    "        \"- N√ÉO adicione explica√ß√µes, apenas a classifica√ß√£o\\n\"\n",
    "        \"- Processe TODAS as transa√ß√µes enviadas\\n\\n\"\n",
    "        \n",
    "        \"Categorias dispon√≠veis: Alimenta√ß√£o, Transporte, Sa√∫de, Mercado, Educa√ß√£o, Lazer,\"\n",
    "        \"Moradia, Investimentos, Streaming, Transfer√™ncias, Outros\\n\\n\"\n",
    "        \n",
    "        \"Transa√ß√µes para categorizar:\\n\" + transactions_text\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    response_lines = [line.strip() for line in response.split('\\n') if line.strip()]\n",
    "\n",
    "    print(\"LLM Response:\")\n",
    "    print(response_lines)\n",
    "\n",
    "    # Process each line and handle different formats\n",
    "    transactions = []\n",
    "    categories = []\n",
    "\n",
    "    for line in response_lines:\n",
    "        if ' - ' in line:\n",
    "            # Split only on the last occurrence of ' - ' para pegar a categoria\n",
    "            parts = line.rsplit(' - ', 1)\n",
    "            if len(parts) == 2:\n",
    "                transaction = parts[0].strip()\n",
    "                category = parts[1].strip()\n",
    "                \n",
    "                # Remove numera√ß√£o se ainda existir\n",
    "                if '. ' in transaction and transaction.split('. ')[0].isdigit():\n",
    "                    transaction = '. '.join(transaction.split('. ')[1:])\n",
    "                \n",
    "                transactions.append(transaction)\n",
    "                categories.append(category)\n",
    "            else:\n",
    "                # Fallback for malformed lines\n",
    "                transactions.append(line.strip())\n",
    "                categories.append(\"N√£o categorizado\")\n",
    "        else:\n",
    "            # Handle lines without separator\n",
    "            if line.strip() and not line.strip().startswith('TRANSA√á√ÉO'):\n",
    "                transactions.append(line.strip())\n",
    "                categories.append(\"N√£o categorizado\")\n",
    "\n",
    "    # Valida√ß√£o: verifica se todas as transa√ß√µes foram processadas\n",
    "    if len(transactions) != len(cleaned_transactions):\n",
    "        print(f\"AVISO: Esperado {len(cleaned_transactions)} transa√ß√µes, mas obteve {len(transactions)}\")\n",
    "        print(f\"Transa√ß√µes originais: {cleaned_transactions}\")\n",
    "        print(f\"Transa√ß√µes processadas: {transactions}\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    categories_df = pd.DataFrame({\n",
    "        'Transaction': transactions,\n",
    "        'Category': categories\n",
    "    })\n",
    "\n",
    "    # Remove empty rows if any\n",
    "    categories_df = categories_df[categories_df['Transaction'] != '']\n",
    "\n",
    "    return categories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01994403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "['Uber - Transporte', 'Parcelamento de Compra - Ppro - Outros', 'Pagamento de boleto efetuado - SERVICO AUTONOMO DE AGUA E ESGOTO DE SALTO - Moradia']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uber</td>\n",
       "      <td>Transporte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parcelamento de Compra - Ppro</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pagamento de boleto efetuado - SERVICO AUTONOM...</td>\n",
       "      <td>Moradia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Transaction    Category\n",
       "0                                               Uber  Transporte\n",
       "1                      Parcelamento de Compra - Ppro      Outros\n",
       "2  Pagamento de boleto efetuado - SERVICO AUTONOM...     Moradia"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorize_transactions('Uber Uber *Trip Help.U, Parcelamento de Compra - Ppro *Microsoft - 1/2, Pagamento de boleto efetuado - SERVICO AUTONOMO DE AGUA E ESGOTO DE SALTO', llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d539dcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Iniciando categoriza√ß√£o de transa√ß√µes...\n",
      "üìÑ Arquivo carregado: 49 transa√ß√µes\n",
      "üìä Total de despesas encontradas: 46\n",
      "üìÅ Cache carregado com 0 entradas\n",
      "üîÑ 46 transa√ß√µes novas para categorizar com LLM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizando:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Enviando bloco de 10 transa√ß√µes para o LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizando:  20%|‚ñà‚ñà        | 1/5 [00:03<00:13,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Resposta do LLM (10 linhas):\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> 99app *99app - Transporte\n",
      "  -> Uber Uber *Trip Help.U - Transporte\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> Uber Uber *Trip Help.U - Transporte\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> Uber Uber *Trip Help.U - Transporte\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> 99app *99app - Transporte\n",
      "  -> Uber Uber *Trip Help.U - Transporte\n",
      "‚úÖ Parsed 10 categorias\n",
      "  ‚úÖ Uber* Trip -> Transporte\n",
      "  ‚úÖ 99app *99app -> Transporte\n",
      "  ‚úÖ Uber Uber *Trip Help.U -> Transporte\n",
      "  ‚úÖ Uber* Trip -> Transporte\n",
      "  ‚úÖ Uber Uber *Trip Help.U -> Transporte\n",
      "  ‚úÖ Uber* Trip -> Transporte\n",
      "  ‚úÖ Uber Uber *Trip Help.U -> Transporte\n",
      "  ‚úÖ Uber* Trip -> Transporte\n",
      "  ‚úÖ 99app *99app -> Transporte\n",
      "  ‚úÖ Uber Uber *Trip Help.U -> Transporte\n",
      "\n",
      "ü§ñ Enviando bloco de 10 transa√ß√µes para o LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizando:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:04<00:06,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Resposta do LLM (10 linhas):\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> 99app *99app - Transporte\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> Sonda Salto Ii - Lazer\n",
      "  -> Dia Brasil Lj - Lazer\n",
      "  -> Dm*Crunchyroll L - Streaming\n",
      "  -> 99app *99app - Transporte\n",
      "  -> 99app *99app - Transporte\n",
      "  -> Ppro *Microsoft - Outros\n",
      "  -> 99app *99app - Transporte\n",
      "‚úÖ Parsed 10 categorias\n",
      "  ‚úÖ Uber* Trip -> Transporte\n",
      "  ‚úÖ 99app *99app -> Transporte\n",
      "  ‚úÖ Uber* Trip -> Transporte\n",
      "  ‚úÖ Sonda Salto Ii -> Lazer\n",
      "  ‚úÖ Dia Brasil Lj -> Lazer\n",
      "  ‚úÖ Dm*Crunchyroll L -> Streaming\n",
      "  ‚úÖ 99app *99app -> Transporte\n",
      "  ‚úÖ 99app *99app -> Transporte\n",
      "  ‚úÖ Ppro *Microsoft -> Outros\n",
      "  ‚úÖ 99app *99app -> Transporte\n",
      "\n",
      "ü§ñ Enviando bloco de 10 transa√ß√µes para o LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizando:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:06<00:03,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Resposta do LLM (10 linhas):\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> Adega 4d - Alimenta√ß√£o\n",
      "  -> 99app *99app - Transfer√™ncias\n",
      "  -> 99app *99app - Transfer√™ncias\n",
      "  -> Uber Uber *Trip Help.U - Transporte\n",
      "  -> Gustavo Moura de Sa - Outros\n",
      "  -> Gustavo Mattos Fortes - Outros\n",
      "  -> 99app *99app - Transfer√™ncias\n",
      "  -> 99app *99app - Transfer√™ncias\n",
      "  -> Parcelamento de Compra - Ppro *Microsoft - Mercado\n",
      "‚úÖ Parsed 10 categorias\n",
      "  ‚úÖ Uber* Trip -> Transporte\n",
      "  ‚úÖ Adega 4d -> Alimenta√ß√£o\n",
      "  ‚úÖ 99app *99app -> Transfer√™ncias\n",
      "  ‚úÖ 99app *99app -> Transfer√™ncias\n",
      "  ‚úÖ Uber Uber *Trip Help.U -> Transporte\n",
      "  ‚úÖ Gustavo Moura de Sa -> Outros\n",
      "  ‚úÖ Gustavo Mattos Fortes -> Outros\n",
      "  ‚úÖ 99app *99app -> Transfer√™ncias\n",
      "  ‚úÖ 99app *99app -> Transfer√™ncias\n",
      "  ‚úÖ Parcelamento de Compra - Ppro *Microsoft -> Mercado\n",
      "\n",
      "ü§ñ Enviando bloco de 10 transa√ß√µes para o LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizando:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:07<00:01,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Resposta do LLM (10 linhas):\n",
      "  -> Parcelamento de Compra - Nove de Julho Conven - Outros\n",
      "  -> Nove de Julho Conven - Outros\n",
      "  -> Blablacar - Transporte\n",
      "  -> 99app *99app - Outros\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> Uber Uber *Trip Help.U - Transporte\n",
      "  -> 99app *99app - Outros\n",
      "  -> Prohumana - Mercado\n",
      "  -> 99app *99app - Outros\n",
      "  -> 99app *99app - Outros\n",
      "‚úÖ Parsed 10 categorias\n",
      "  ‚úÖ Parcelamento de Compra - Nove de Julho Conven -> Outros\n",
      "  ‚úÖ Nove de Julho Conven -> Outros\n",
      "  ‚úÖ Blablacar -> Transporte\n",
      "  ‚úÖ 99app *99app -> Outros\n",
      "  ‚úÖ Uber* Trip -> Transporte\n",
      "  ‚úÖ Uber Uber *Trip Help.U -> Transporte\n",
      "  ‚úÖ 99app *99app -> Outros\n",
      "  ‚úÖ Prohumana -> Mercado\n",
      "  ‚úÖ 99app *99app -> Outros\n",
      "  ‚úÖ 99app *99app -> Outros\n",
      "\n",
      "ü§ñ Enviando bloco de 6 transa√ß√µes para o LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:08<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Resposta do LLM (6 linhas):\n",
      "  -> Parcelamento de Compra - Sonda Salto Ii - Mercado\n",
      "  -> Uber Uber *Trip Help.U - Transporte\n",
      "  -> Parcelamento de Compra - Sonda Salto Ii - Mercado\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> Parcelamento de Compra - Microsoft*Subscription - Educa√ß√£o\n",
      "  -> Parcelamento de Compra - Fatimo Volmir Oliveir - Outros\n",
      "‚úÖ Parsed 6 categorias\n",
      "  ‚úÖ Parcelamento de Compra - Sonda Salto Ii -> Mercado\n",
      "  ‚úÖ Uber Uber *Trip Help.U -> Transporte\n",
      "  ‚úÖ Parcelamento de Compra - Sonda Salto Ii -> Mercado\n",
      "  ‚úÖ Uber* Trip -> Transporte\n",
      "  ‚úÖ Parcelamento de Compra - Microsoft*Subscription -> Educa√ß√£o\n",
      "  ‚úÖ Parcelamento de Compra - Fatimo Volmir Oliveir -> Outros\n",
      "üíæ Cache salvo com 18 entradas\n",
      "\n",
      "üìã Resumo das categorias:\n",
      "Categoria\n",
      "Outros         20\n",
      "Transporte     17\n",
      "Mercado         4\n",
      "Lazer           2\n",
      "Streaming       1\n",
      "Alimenta√ß√£o     1\n",
      "Educa√ß√£o        1\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Arquivo final salvo como 'extrato_categorizados_final.csv'\n",
      "\n",
      "üìä Estat√≠sticas finais:\n",
      "Total de transa√ß√µes: 343\n",
      "Despesas categorizadas: 340\n",
      "Receitas/Cr√©ditos: 3\n",
      "\n",
      "üè∑Ô∏è Distribui√ß√£o de categorias:\n",
      "  Outros: 202\n",
      "  Transporte: 129\n",
      "  Mercado: 4\n",
      "  Lazer: 2\n",
      "  Streaming: 1\n",
      "  Alimenta√ß√£o: 1\n",
      "  Educa√ß√£o: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema import HumanMessage\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ======== CONFIGURA√á√ïES ========\n",
    "OLLAMA_MODEL = \"gemma3\"\n",
    "CSV_PATH = \"C:/Users/Bruno/Downloads/Nubank_2025-06-19.csv\"\n",
    "DESCRICAO_COL = \"title\"\n",
    "VALOR_COL = \"amount\"\n",
    "CACHE_PATH = \"categorias_cache.pkl\"\n",
    "BLOCO_TAMANHO = 10\n",
    "\n",
    "# ======== CACHE ========\n",
    "def load_cache(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "# ======== LIMPEZA E PROMPT ========\n",
    "def clean_transaction_name(transaction_name):\n",
    "    \"\"\"Limpa o nome da transa√ß√£o para padroniza√ß√£o\"\"\"\n",
    "    parts = transaction_name.split(' - ')\n",
    "    return ' - '.join(parts[:2]) if len(parts) > 2 else transaction_name\n",
    "\n",
    "def generate_prompt(transactions):\n",
    "    \"\"\"Gera prompt para categoriza√ß√£o em lote\"\"\"\n",
    "    formatted = '\\n'.join(f\"{i+1}. {clean_transaction_name(t)}\" for i, t in enumerate(transactions))\n",
    "    prompt = f\"\"\"\n",
    "Voc√™ √© um especialista em an√°lise de finan√ßas pessoais.\n",
    "\n",
    "REGRAS IMPORTANTES:\n",
    "- Retorne EXATAMENTE no formato: 'TRANSA√á√ÉO - CATEGORIA'\n",
    "- Use os nomes das transa√ß√µes EXATAMENTE como fornecidos (ap√≥s limpeza)\n",
    "- Categorias poss√≠veis: Alimenta√ß√£o, Transporte, Sa√∫de, Mercado, Educa√ß√£o, Lazer, Moradia, Investimentos, Streaming, Transfer√™ncias, Outros\n",
    "- N√£o adicione numera√ß√£o, explica√ß√µes ou coment√°rios extras\n",
    "- Categorize TODAS as {len(transactions)} transa√ß√µes listadas abaixo:\n",
    "\n",
    "Transa√ß√µes:\n",
    "{formatted}\n",
    "\n",
    "Exemplo de formato esperado:\n",
    "Uber* Trip - Transporte\n",
    "Netflix - Streaming\n",
    "Supermercado XYZ - Mercado\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "def parse_llm_response(response, original_transactions):\n",
    "    \"\"\"Parse da resposta do LLM com valida√ß√£o\"\"\"\n",
    "    lines = [line.strip() for line in response.split('\\n') if line.strip()]\n",
    "    parsed = []\n",
    "    \n",
    "    print(f\"üîç Resposta do LLM ({len(lines)} linhas):\")\n",
    "    for line in lines:\n",
    "        print(f\"  -> {line}\")\n",
    "    \n",
    "    # Tentar diferentes formatos de parsing\n",
    "    for line in lines:\n",
    "        if ' - ' in line:\n",
    "            # Formato padr√£o: \"Transa√ß√£o - Categoria\"\n",
    "            trans, cat = line.rsplit(' - ', 1)\n",
    "            parsed.append((trans.strip(), cat.strip()))\n",
    "        elif ':' in line and not line.startswith(('Exemplo', 'Categorias')):\n",
    "            # Formato alternativo: \"Transa√ß√£o: Categoria\"\n",
    "            trans, cat = line.split(':', 1)\n",
    "            parsed.append((trans.strip(), cat.strip()))\n",
    "    \n",
    "    print(f\"‚úÖ Parsed {len(parsed)} categorias\")\n",
    "    return parsed\n",
    "\n",
    "# ======== CATEGORIZA√á√ÉO COM CACHE E BLOCOS ========\n",
    "def categorize_transactions_in_blocks(df, model_name=OLLAMA_MODEL, bloco_tamanho=BLOCO_TAMANHO):\n",
    "    \"\"\"Categoriza transa√ß√µes usando cache e processamento em blocos\"\"\"\n",
    "    \n",
    "    # Filtrar apenas despesas (valores positivos no seu caso)\n",
    "    df_despesas = df[df[VALOR_COL] > 0].copy()\n",
    "    transacoes = df_despesas[DESCRICAO_COL].tolist()\n",
    "    \n",
    "    print(f\"üìä Total de despesas encontradas: {len(transacoes)}\")\n",
    "    \n",
    "    cache = load_cache(CACHE_PATH)\n",
    "    print(f\"üìÅ Cache carregado com {len(cache)} entradas\")\n",
    "    \n",
    "    llm = ChatOllama(model=model_name)\n",
    "    \n",
    "    # Verificar quais transa√ß√µes precisam ser categorizadas\n",
    "    transacoes_para_categorizar = []\n",
    "    indices_para_categorizar = []\n",
    "    \n",
    "    for idx, t in enumerate(transacoes):\n",
    "        t_clean = clean_transaction_name(t)\n",
    "        if t_clean not in cache:\n",
    "            transacoes_para_categorizar.append(t)\n",
    "            indices_para_categorizar.append(idx)\n",
    "    \n",
    "    print(f\"üîÑ {len(transacoes_para_categorizar)} transa√ß√µes novas para categorizar com LLM.\")\n",
    "    \n",
    "    # Processar transa√ß√µes n√£o cachadas por blocos\n",
    "    if transacoes_para_categorizar:\n",
    "        for i in tqdm(range(0, len(transacoes_para_categorizar), bloco_tamanho), desc=\"Categorizando\"):\n",
    "            bloco = transacoes_para_categorizar[i:i+bloco_tamanho]\n",
    "            prompt = generate_prompt(bloco)\n",
    "            \n",
    "            try:\n",
    "                print(f\"\\nü§ñ Enviando bloco de {len(bloco)} transa√ß√µes para o LLM...\")\n",
    "                resposta = llm.invoke([HumanMessage(content=prompt)])\n",
    "                resultado = parse_llm_response(resposta.content, bloco)\n",
    "                \n",
    "                # Salvar no cache\n",
    "                for trans, cat in resultado:\n",
    "                    t_clean = clean_transaction_name(trans)\n",
    "                    cache[t_clean] = cat\n",
    "                    print(f\"  ‚úÖ {t_clean} -> {cat}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erro ao processar bloco: {e}\")\n",
    "                # Em caso de erro, categorizar como \"Outros\"\n",
    "                for trans in bloco:\n",
    "                    t_clean = clean_transaction_name(trans)\n",
    "                    cache[t_clean] = \"Outros\"\n",
    "    \n",
    "    # Salvar cache atualizado\n",
    "    save_cache(cache, CACHE_PATH)\n",
    "    print(f\"üíæ Cache salvo com {len(cache)} entradas\")\n",
    "    \n",
    "    # Aplicar categorias a todas as transa√ß√µes\n",
    "    categorias_finais = []\n",
    "    for t in transacoes:\n",
    "        t_clean = clean_transaction_name(t)\n",
    "        categoria = cache.get(t_clean, \"N√£o categorizado\")\n",
    "        categorias_finais.append(categoria)\n",
    "    \n",
    "    df_despesas['Categoria'] = categorias_finais\n",
    "    \n",
    "    # Debug: mostrar resultado\n",
    "    print(\"\\nüìã Resumo das categorias:\")\n",
    "    print(df_despesas['Categoria'].value_counts())\n",
    "    \n",
    "    return df_despesas\n",
    "\n",
    "# ======== EXECU√á√ÉO PRINCIPAL ========\n",
    "def main():\n",
    "    \"\"\"Fun√ß√£o principal\"\"\"\n",
    "    print(\"üöÄ Iniciando categoriza√ß√£o de transa√ß√µes...\")\n",
    "    \n",
    "    # Carregar dados\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_PATH)\n",
    "        print(f\"üìÑ Arquivo carregado: {len(df)} transa√ß√µes\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Arquivo n√£o encontrado: {CSV_PATH}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar arquivo: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Remover coluna Identificador se existir\n",
    "    if 'Identificador' in df.columns:\n",
    "        df.drop(columns=['Identificador'], inplace=True)\n",
    "        print(\"üóëÔ∏è Coluna 'Identificador' removida\")\n",
    "    \n",
    "    # Verificar se as colunas necess√°rias existem\n",
    "    if DESCRICAO_COL not in df.columns or VALOR_COL not in df.columns:\n",
    "        print(f\"‚ùå Colunas necess√°rias n√£o encontradas. Esperado: {DESCRICAO_COL}, {VALOR_COL}\")\n",
    "        print(f\"Colunas encontradas: {list(df.columns)}\")\n",
    "        return\n",
    "    \n",
    "    # Categorizar transa√ß√µes\n",
    "    df_categorizado = categorize_transactions_in_blocks(df, model_name=OLLAMA_MODEL, bloco_tamanho=BLOCO_TAMANHO)\n",
    "    \n",
    "    # Fazer merge com dados originais\n",
    "    df_final = df.merge(\n",
    "        df_categorizado[[DESCRICAO_COL, 'Categoria']], \n",
    "        on=DESCRICAO_COL, \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Preencher categorias vazias (receitas/transfer√™ncias ficam sem categoria ou com categoria espec√≠fica)\n",
    "    df_final['Categoria'] = df_final['Categoria'].fillna('')\n",
    "    \n",
    "    # Aplicar l√≥gica espec√≠fica para valores negativos\n",
    "    mask_negativos = df_final[VALOR_COL] < 0\n",
    "    df_final.loc[mask_negativos & df_final['Categoria'].isna(), 'Categoria'] = 'Receita'\n",
    "    \n",
    "    # Salvar resultado\n",
    "    output_path = \"extrato_categorizados_final.csv\"\n",
    "    df_final.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Arquivo final salvo como '{output_path}'\")\n",
    "    \n",
    "    # Mostrar estat√≠sticas finais\n",
    "    print(f\"\\nüìä Estat√≠sticas finais:\")\n",
    "    print(f\"Total de transa√ß√µes: {len(df_final)}\")\n",
    "    print(f\"Despesas categorizadas: {len(df_final[df_final[VALOR_COL] > 0])}\")\n",
    "    print(f\"Receitas/Cr√©ditos: {len(df_final[df_final[VALOR_COL] <= 0])}\")\n",
    "    \n",
    "    # Mostrar distribui√ß√£o de categorias\n",
    "    categorias_count = df_final[df_final['Categoria'] != '']['Categoria'].value_counts()\n",
    "    print(f\"\\nüè∑Ô∏è Distribui√ß√£o de categorias:\")\n",
    "    for cat, count in categorias_count.items():\n",
    "        print(f\"  {cat}: {count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d03f04c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Iniciando categoriza√ß√£o de transa√ß√µes...\n",
      "üìÑ Arquivo carregado: 49 transa√ß√µes\n",
      "üìä Total de despesas encontradas: 46\n",
      "üìÅ Cache carregado com 0 entradas\n",
      "üîÑ 46 transa√ß√µes novas para categorizar com LLM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizando:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Enviando bloco de 10 transa√ß√µes para o LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizando:  20%|‚ñà‚ñà        | 1/5 [00:02<00:11,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Resposta do LLM (10 linhas):\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> 99app *99app - Transporte\n",
      "  -> Uber Uber *Trip Help.U - Transporte\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> Uber Uber *Trip Help.U - Transporte\n",
      "‚úÖ Parsed 10 categorias de 10 transa√ß√µes\n",
      "  ‚úÖ Uber* Trip -> Transporte\n",
      "  ‚úÖ 99app *99app -> Transporte\n",
      "  ‚úÖ Uber Uber *Trip Help.U -> Transporte\n",
      "  ‚è≠Ô∏è Uber* Trip j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è Uber Uber *Trip Help.U j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è Uber* Trip j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è Uber Uber *Trip Help.U j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è Uber* Trip j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è Uber Uber *Trip Help.U j√° existe no cache: Transporte\n",
      "\n",
      "ü§ñ Enviando bloco de 10 transa√ß√µes para o LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizando:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:04<00:05,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Resposta do LLM (10 linhas):\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> 99app *99app - Transporte\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> Sonda Salto Ii - Lazer\n",
      "  -> Dia Brasil Lj - Alimenta√ß√£o\n",
      "‚úÖ Parsed 10 categorias de 10 transa√ß√µes\n",
      "  ‚è≠Ô∏è Uber* Trip j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è Uber* Trip j√° existe no cache: Transporte\n",
      "  ‚úÖ Sonda Salto Ii -> Lazer\n",
      "  ‚úÖ Dia Brasil Lj -> Alimenta√ß√£o\n",
      "  ‚úÖ Dm*Crunchyroll L -> Streaming\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "  ‚úÖ Ppro *Microsoft -> Outros\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "\n",
      "ü§ñ Enviando bloco de 10 transa√ß√µes para o LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizando:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:05<00:03,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Resposta do LLM (10 linhas):\n",
      "  -> Adega 4d - Alimenta√ß√£o\n",
      "  -> Uber Uber *Trip Help.U - Transporte\n",
      "  -> 99app *99app - Outros\n",
      "  -> 99app *99app - Outros\n",
      "  -> Uber Uber *Trip Help.U - Transporte\n",
      "‚úÖ Parsed 10 categorias de 10 transa√ß√µes\n",
      "  ‚úÖ Adega 4d -> Alimenta√ß√£o\n",
      "  ‚è≠Ô∏è Uber Uber *Trip Help.U j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è Uber Uber *Trip Help.U j√° existe no cache: Transporte\n",
      "  ‚úÖ Gustavo Moura de Sa -> Transfer√™ncias\n",
      "  ‚úÖ Gustavo Mattos Fortes -> Transfer√™ncias\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "  ‚úÖ Parcelamento de Compra - Ppro *Microsoft -> Mercado\n",
      "\n",
      "ü§ñ Enviando bloco de 10 transa√ß√µes para o LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizando:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:07<00:01,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Resposta do LLM (10 linhas):\n",
      "  -> Parcelamento de Compra - Nove de Julho Conven - Outros\n",
      "  -> Nove de Julho Conven - Outros\n",
      "  -> Blablacar - Transporte\n",
      "  -> 99app *99app - Mercado\n",
      "  -> Uber* Trip - Transporte\n",
      "‚úÖ Parsed 10 categorias de 10 transa√ß√µes\n",
      "  ‚úÖ Parcelamento de Compra - Nove de Julho Conven -> Outros\n",
      "  ‚úÖ Nove de Julho Conven -> Outros\n",
      "  ‚úÖ Blablacar -> Transporte\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è Uber* Trip j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è Uber Uber *Trip Help.U j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "  ‚úÖ Prohumana -> Mercado\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è 99app *99app j√° existe no cache: Transporte\n",
      "\n",
      "ü§ñ Enviando bloco de 6 transa√ß√µes para o LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:08<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Resposta do LLM (6 linhas):\n",
      "  -> Parcelamento de Compra - Sonda Salto Ii - Mercado\n",
      "  -> Uber Uber *Trip Help.U - Transporte\n",
      "  -> Parcelamento de Compra - Sonda Salto Ii - Mercado\n",
      "  -> Uber* Trip - Transporte\n",
      "  -> Parcelamento de Compra - Microsoft*Subscription - Educa√ß√£o\n",
      "‚úÖ Parsed 6 categorias de 6 transa√ß√µes\n",
      "  ‚úÖ Parcelamento de Compra - Sonda Salto Ii -> Mercado\n",
      "  ‚è≠Ô∏è Uber Uber *Trip Help.U j√° existe no cache: Transporte\n",
      "  ‚è≠Ô∏è Parcelamento de Compra - Sonda Salto Ii j√° existe no cache: Mercado\n",
      "  ‚è≠Ô∏è Uber* Trip j√° existe no cache: Transporte\n",
      "  ‚úÖ Parcelamento de Compra - Microsoft*Subscription -> Educa√ß√£o\n",
      "  ‚úÖ Parcelamento de Compra - Fatimo Volmir Oliveir -> Outros\n",
      "üíæ Cache salvo com 18 entradas\n",
      "\n",
      "üìã Resumo das categorias:\n",
      "Categoria\n",
      "Transporte        31\n",
      "Outros             4\n",
      "Mercado            4\n",
      "Alimenta√ß√£o        2\n",
      "Transfer√™ncias     2\n",
      "Lazer              1\n",
      "Streaming          1\n",
      "Educa√ß√£o           1\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Arquivo final salvo como 'extrato_categorizados_final.csv'\n",
      "\n",
      "üìä Estat√≠sticas finais:\n",
      "Total de transa√ß√µes: 49\n",
      "Despesas categorizadas: 46\n",
      "Receitas/Cr√©ditos: 3\n",
      "\n",
      "üè∑Ô∏è Distribui√ß√£o de categorias:\n",
      "  Transporte: 31\n",
      "  Outros: 4\n",
      "  Mercado: 4\n",
      "  Alimenta√ß√£o: 2\n",
      "  Transfer√™ncias: 2\n",
      "  Lazer: 1\n",
      "  Streaming: 1\n",
      "  Educa√ß√£o: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema import HumanMessage\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ======== CONFIGURA√á√ïES ========\n",
    "OLLAMA_MODEL = \"gemma3\"\n",
    "CSV_PATH = \"C:/Users/Bruno/Downloads/Nubank_2025-06-19.csv\"\n",
    "DESCRICAO_COL = \"title\"\n",
    "VALOR_COL = \"amount\"\n",
    "CACHE_PATH = \"categorias_cache.pkl\"\n",
    "BLOCO_TAMANHO = 10\n",
    "\n",
    "# ======== CACHE ========\n",
    "def load_cache(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "# ======== LIMPEZA E PROMPT ========\n",
    "def clean_transaction_name(transaction_name):\n",
    "    \"\"\"Limpa o nome da transa√ß√£o para padroniza√ß√£o\"\"\"\n",
    "    parts = transaction_name.split(' - ')\n",
    "    return ' - '.join(parts[:2]) if len(parts) > 2 else transaction_name\n",
    "\n",
    "def generate_prompt(transactions):\n",
    "    \"\"\"Gera prompt para categoriza√ß√£o em lote\"\"\"\n",
    "    formatted = '\\n'.join(f\"{i+1}. {clean_transaction_name(t)}\" for i, t in enumerate(transactions))\n",
    "    prompt = f\"\"\"\n",
    "Voc√™ √© um especialista em an√°lise de finan√ßas pessoais.\n",
    "\n",
    "REGRAS IMPORTANTES:\n",
    "- Retorne EXATAMENTE no formato: 'TRANSA√á√ÉO - CATEGORIA'\n",
    "- Use os nomes das transa√ß√µes EXATAMENTE como fornecidos (ap√≥s limpeza)\n",
    "- Categorias poss√≠veis: Alimenta√ß√£o, Transporte, Sa√∫de, Mercado, Educa√ß√£o, Lazer, Moradia, Investimentos, Streaming, Transfer√™ncias, Outros\n",
    "- N√£o adicione numera√ß√£o, explica√ß√µes ou coment√°rios extras\n",
    "- Categorize TODAS as {len(transactions)} transa√ß√µes listadas abaixo:\n",
    "\n",
    "Transa√ß√µes:\n",
    "{formatted}\n",
    "\n",
    "Exemplo de formato esperado:\n",
    "Uber* Trip - Transporte\n",
    "Netflix - Streaming\n",
    "Supermercado XYZ - Mercado\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "def parse_llm_response(response, original_transactions):\n",
    "    \"\"\"Parse da resposta do LLM com valida√ß√£o melhorada\"\"\"\n",
    "    lines = [line.strip() for line in response.split('\\n') if line.strip()]\n",
    "    parsed = []\n",
    "    \n",
    "    print(f\"üîç Resposta do LLM ({len(lines)} linhas):\")\n",
    "    for line in lines[:5]:  # Mostrar apenas as primeiras 5 linhas\n",
    "        print(f\"  -> {line}\")\n",
    "    \n",
    "    # Criar mapeamento das transa√ß√µes originais limpas\n",
    "    trans_originais = {clean_transaction_name(t): t for t in original_transactions}\n",
    "    \n",
    "    # Tentar diferentes formatos de parsing\n",
    "    for line in lines:\n",
    "        if ' - ' in line:\n",
    "            # Formato padr√£o: \"Transa√ß√£o - Categoria\"\n",
    "            trans, cat = line.rsplit(' - ', 1)\n",
    "            trans_clean = trans.strip()\n",
    "            cat_clean = cat.strip()\n",
    "            \n",
    "            # Verificar se a transa√ß√£o existe nas originais\n",
    "            if trans_clean in trans_originais:\n",
    "                parsed.append((trans_clean, cat_clean))\n",
    "            else:\n",
    "                # Tentar match parcial\n",
    "                for orig_clean, orig_full in trans_originais.items():\n",
    "                    if trans_clean in orig_clean or orig_clean in trans_clean:\n",
    "                        parsed.append((orig_clean, cat_clean))\n",
    "                        break\n",
    "        elif ':' in line and not line.startswith(('Exemplo', 'Categorias', 'Transa√ß√µes')):\n",
    "            # Formato alternativo: \"Transa√ß√£o: Categoria\"\n",
    "            trans, cat = line.split(':', 1)\n",
    "            trans_clean = trans.strip()\n",
    "            cat_clean = cat.strip()\n",
    "            \n",
    "            if trans_clean in trans_originais:\n",
    "                parsed.append((trans_clean, cat_clean))\n",
    "    \n",
    "    print(f\"‚úÖ Parsed {len(parsed)} categorias de {len(original_transactions)} transa√ß√µes\")\n",
    "    return parsed\n",
    "\n",
    "# ======== CATEGORIZA√á√ÉO COM CACHE E BLOCOS ========\n",
    "def categorize_transactions_in_blocks(df, model_name=OLLAMA_MODEL, bloco_tamanho=BLOCO_TAMANHO):\n",
    "    \"\"\"Categoriza transa√ß√µes usando cache e processamento em blocos\"\"\"\n",
    "    \n",
    "    # Filtrar apenas despesas (valores positivos no seu caso)\n",
    "    df_despesas = df[df[VALOR_COL] > 0].copy()\n",
    "    transacoes = df_despesas[DESCRICAO_COL].tolist()\n",
    "    \n",
    "    print(f\"üìä Total de despesas encontradas: {len(transacoes)}\")\n",
    "    \n",
    "    cache = load_cache(CACHE_PATH)\n",
    "    print(f\"üìÅ Cache carregado com {len(cache)} entradas\")\n",
    "    \n",
    "    llm = ChatOllama(model=model_name)\n",
    "    \n",
    "    # Verificar quais transa√ß√µes precisam ser categorizadas\n",
    "    transacoes_para_categorizar = []\n",
    "    indices_para_categorizar = []\n",
    "    \n",
    "    for idx, t in enumerate(transacoes):\n",
    "        t_clean = clean_transaction_name(t)\n",
    "        if t_clean not in cache:\n",
    "            transacoes_para_categorizar.append(t)\n",
    "            indices_para_categorizar.append(idx)\n",
    "    \n",
    "    print(f\"üîÑ {len(transacoes_para_categorizar)} transa√ß√µes novas para categorizar com LLM.\")\n",
    "    \n",
    "    # Processar transa√ß√µes n√£o cachadas por blocos\n",
    "    if transacoes_para_categorizar:\n",
    "        for i in tqdm(range(0, len(transacoes_para_categorizar), bloco_tamanho), desc=\"Categorizando\"):\n",
    "            bloco = transacoes_para_categorizar[i:i+bloco_tamanho]\n",
    "            prompt = generate_prompt(bloco)\n",
    "            \n",
    "            try:\n",
    "                print(f\"\\nü§ñ Enviando bloco de {len(bloco)} transa√ß√µes para o LLM...\")\n",
    "                resposta = llm.invoke([HumanMessage(content=prompt)])\n",
    "                resultado = parse_llm_response(resposta.content, bloco)\n",
    "                \n",
    "                # Salvar no cache apenas se o parsing foi bem-sucedido\n",
    "                if len(resultado) > 0:\n",
    "                    for trans, cat in resultado:\n",
    "                        t_clean = clean_transaction_name(trans)\n",
    "                        # S√≥ adiciona ao cache se n√£o existir ou se a categoria anterior era \"Outros\"\n",
    "                        if t_clean not in cache or cache[t_clean] == \"Outros\":\n",
    "                            cache[t_clean] = cat\n",
    "                            print(f\"  ‚úÖ {t_clean} -> {cat}\")\n",
    "                        else:\n",
    "                            print(f\"  ‚è≠Ô∏è {t_clean} j√° existe no cache: {cache[t_clean]}\")\n",
    "                else:\n",
    "                    print(f\"  ‚ö†Ô∏è Nenhuma categoria parseada do LLM\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erro ao processar bloco: {e}\")\n",
    "                # Em caso de erro, categorizar como \"Outros\"\n",
    "                for trans in bloco:\n",
    "                    t_clean = clean_transaction_name(trans)\n",
    "                    cache[t_clean] = \"Outros\"\n",
    "    \n",
    "    # Salvar cache atualizado ap√≥s cada bloco\n",
    "        if transacoes_para_categorizar:\n",
    "            save_cache(cache, CACHE_PATH)\n",
    "        \n",
    "        print(f\"üíæ Cache salvo com {len(cache)} entradas\")\n",
    "    \n",
    "    # Aplicar categorias a todas as transa√ß√µes\n",
    "    categorias_finais = []\n",
    "    for t in transacoes:\n",
    "        t_clean = clean_transaction_name(t)\n",
    "        categoria = cache.get(t_clean, \"N√£o categorizado\")\n",
    "        categorias_finais.append(categoria)\n",
    "    \n",
    "    df_despesas['Categoria'] = categorias_finais\n",
    "    \n",
    "    # Debug: mostrar resultado\n",
    "    print(\"\\nüìã Resumo das categorias:\")\n",
    "    print(df_despesas['Categoria'].value_counts())\n",
    "    \n",
    "    return df_despesas\n",
    "\n",
    "# ======== EXECU√á√ÉO PRINCIPAL ========\n",
    "def main():\n",
    "    \"\"\"Fun√ß√£o principal\"\"\"\n",
    "    print(\"üöÄ Iniciando categoriza√ß√£o de transa√ß√µes...\")\n",
    "    \n",
    "    # Carregar dados\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_PATH)\n",
    "        print(f\"üìÑ Arquivo carregado: {len(df)} transa√ß√µes\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Arquivo n√£o encontrado: {CSV_PATH}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar arquivo: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Remover coluna Identificador se existir\n",
    "    if 'Identificador' in df.columns:\n",
    "        df.drop(columns=['Identificador'], inplace=True)\n",
    "        print(\"üóëÔ∏è Coluna 'Identificador' removida\")\n",
    "    \n",
    "    # Verificar se as colunas necess√°rias existem\n",
    "    if DESCRICAO_COL not in df.columns or VALOR_COL not in df.columns:\n",
    "        print(f\"‚ùå Colunas necess√°rias n√£o encontradas. Esperado: {DESCRICAO_COL}, {VALOR_COL}\")\n",
    "        print(f\"Colunas encontradas: {list(df.columns)}\")\n",
    "        return\n",
    "    \n",
    "    # Categorizar transa√ß√µes\n",
    "    df_categorizado = categorize_transactions_in_blocks(df, model_name=OLLAMA_MODEL, bloco_tamanho=BLOCO_TAMANHO)\n",
    "    \n",
    "    # Fazer merge com dados originais (evitando duplicatas)\n",
    "    df_categorizado_unique = df_categorizado[[DESCRICAO_COL, 'Categoria']].drop_duplicates(subset=[DESCRICAO_COL])\n",
    "    \n",
    "    df_final = df.merge(\n",
    "        df_categorizado_unique, \n",
    "        on=DESCRICAO_COL, \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Preencher categorias vazias (receitas/transfer√™ncias ficam sem categoria ou com categoria espec√≠fica)\n",
    "    df_final['Categoria'] = df_final['Categoria'].fillna('')\n",
    "    \n",
    "    # Aplicar l√≥gica espec√≠fica para valores negativos\n",
    "    mask_negativos = df_final[VALOR_COL] < 0\n",
    "    df_final.loc[mask_negativos & df_final['Categoria'].isna(), 'Categoria'] = 'Receita'\n",
    "    \n",
    "    # Salvar resultado\n",
    "    output_path = \"extrato_categorizados_final.csv\"\n",
    "    df_final.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Arquivo final salvo como '{output_path}'\")\n",
    "    \n",
    "    # Mostrar estat√≠sticas finais\n",
    "    print(f\"\\nüìä Estat√≠sticas finais:\")\n",
    "    print(f\"Total de transa√ß√µes: {len(df_final)}\")\n",
    "    print(f\"Despesas categorizadas: {len(df_final[df_final[VALOR_COL] > 0])}\")\n",
    "    print(f\"Receitas/Cr√©ditos: {len(df_final[df_final[VALOR_COL] <= 0])}\")\n",
    "    \n",
    "    # Mostrar distribui√ß√£o de categorias\n",
    "    categorias_count = df_final[df_final['Categoria'] != '']['Categoria'].value_counts()\n",
    "    print(f\"\\nüè∑Ô∏è Distribui√ß√£o de categorias:\")\n",
    "    for cat, count in categorias_count.items():\n",
    "        print(f\"  {cat}: {count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
